{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Colab Owner: Darshil Modi [linkedin: https://www.linkedin.com/in/darshil3011] [email: darshil3011@gmail.com]\n",
        "\n",
        "Built upon: https://github.com/fkodom/yet-another-retnet/\n",
        "\n",
        "Paper link: https://arxiv.org/pdf/2307.08621.pdf\n",
        "\n",
        "Check out my other projects on https://www.github.com/darshil3011"
      ],
      "metadata": {
        "id": "ed7DfQg01rGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies and Clone github repo"
      ],
      "metadata": {
        "id": "Tu9PqlhkDDaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yet-another-retnet[train]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ8_s1Kl-ebb",
        "outputId": "77f11e4b-f602-45a7-d4c9-6f645c61146a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yet-another-retnet[train] in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (0.7.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (2.0.1)\n",
            "Requirement already satisfied: tensorboard~=2.14.0 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (2.14.1)\n",
            "Requirement already satisfied: tiktoken~=0.4.0 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (0.4.0)\n",
            "Requirement already satisfied: torchdata>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet[train]) (4.66.2)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (3.1.3)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (6.0.1)\n",
            "Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (4.12.3)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (8.1.7)\n",
            "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.3.15)\n",
            "Requirement already satisfied: dateutils<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.6.12)\n",
            "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (6.7.1)\n",
            "Requirement already satisfied: fastapi<0.89.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.88.0)\n",
            "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (2023.6.0)\n",
            "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (3.2.3)\n",
            "Requirement already satisfied: lightning-cloud>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.5.64)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.10.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (23.2)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.10.14)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (2.31.0)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (13.7.0)\n",
            "Requirement already satisfied: starlette<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.22.0)\n",
            "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.3.0)\n",
            "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.3.1)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (4.9.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (2.0.7)\n",
            "Requirement already satisfied: uvicorn<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (0.27.1)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (1.7.0)\n",
            "Requirement already satisfied: websockets<12.0 in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (11.0.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning~=2.0.0->yet-another-retnet[train]) (2.2.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (3.5.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard~=2.14.0->yet-another-retnet[train]) (3.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken~=0.4.0->yet-another-retnet[train]) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet[train]) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet[train]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet[train]) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet[train]) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning~=2.0.0->yet-another-retnet[train]) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning~=2.0.0->yet-another-retnet[train]) (2.8.19.20240106)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning~=2.0.0->yet-another-retnet[train]) (2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning~=2.0.0->yet-another-retnet[train]) (2023.4)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff<8.0,>=5.7.0->lightning~=2.0.0->yet-another-retnet[train]) (4.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<2.0->lightning~=2.0.0->yet-another-retnet[train]) (3.7.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (3.9.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.14.0->yet-another-retnet[train]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.14.0->yet-another-retnet[train]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.14.0->yet-another-retnet[train]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.14.0->yet-another-retnet[train]) (1.3.1)\n",
            "Requirement already satisfied: blessed>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (1.20.0)\n",
            "Requirement already satisfied: editor>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (1.6.6)\n",
            "Requirement already satisfied: readchar>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (4.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning~=2.0.0->yet-another-retnet[train]) (2.1.5)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (2.3.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (0.0.9)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (1.34.42)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning~=2.0.0->yet-another-retnet[train]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning~=2.0.0->yet-another-retnet[train]) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning~=2.0.0->yet-another-retnet[train]) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning~=2.0.0->yet-another-retnet[train]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning~=2.0.0->yet-another-retnet[train]) (2.16.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning~=2.0.0->yet-another-retnet[train]) (2.1.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<2.0->lightning~=2.0.0->yet-another-retnet[train]) (0.14.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->yet-another-retnet[train]) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning~=2.0.0->yet-another-retnet[train]) (4.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning~=2.0.0->yet-another-retnet[train]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning~=2.0.0->yet-another-retnet[train]) (1.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (0.2.13)\n",
            "Requirement already satisfied: runs in /usr/local/lib/python3.10/dist-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (1.2.2)\n",
            "Requirement already satisfied: xmod in /usr/local/lib/python3.10/dist-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning~=2.0.0->yet-another-retnet[train]) (1.8.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning~=2.0.0->yet-another-retnet[train]) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.14.0->yet-another-retnet[train]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.14.0->yet-another-retnet[train]) (3.2.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.42 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (1.34.43)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning~=2.0.0->yet-another-retnet[train]) (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fkodom/yet-another-retnet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRjloXAnuDlf",
        "outputId": "b1b45d39-c10c-4d0f-9a93-745d26f494a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yet-another-retnet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning==2.0.1\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrqAb7Qyui35",
        "outputId": "7e8a5939-8bfd-4f21-d636-4540d39c2663"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (3.1.3)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (6.0.1)\n",
            "Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (4.12.3)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (8.1.7)\n",
            "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.3.15)\n",
            "Requirement already satisfied: dateutils<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.6.12)\n",
            "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (6.7.1)\n",
            "Requirement already satisfied: fastapi<0.89.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.88.0)\n",
            "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (2023.6.0)\n",
            "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (3.2.3)\n",
            "Requirement already satisfied: lightning-cloud>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.5.64)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.10.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (23.2)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.10.14)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (2.31.0)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (13.7.0)\n",
            "Requirement already satisfied: starlette<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.22.0)\n",
            "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (4.66.2)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (4.9.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (2.0.7)\n",
            "Requirement already satisfied: uvicorn<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (0.27.1)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (1.7.0)\n",
            "Requirement already satisfied: websockets<12.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (11.0.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.1) (2.2.0.post0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning==2.0.1) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning==2.0.1) (2.8.19.20240106)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning==2.0.1) (2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning==2.0.1) (2023.4)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff<8.0,>=5.7.0->lightning==2.0.1) (4.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<2.0->lightning==2.0.1) (3.7.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (3.9.3)\n",
            "Requirement already satisfied: blessed>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.1) (1.20.0)\n",
            "Requirement already satisfied: editor>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.1) (1.6.6)\n",
            "Requirement already satisfied: readchar>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.1) (4.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.31->lightning==2.0.1) (2.3.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.31->lightning==2.0.1) (0.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.31->lightning==2.0.1) (1.16.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.31->lightning==2.0.1) (1.34.42)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.7.0->lightning==2.0.1) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.1) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.1) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning==2.0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning==2.0.1) (2.16.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning==2.0.1) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.1) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.1) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.1) (2.1.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<2.0->lightning==2.0.1) (0.14.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning==2.0.1) (4.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning==2.0.1) (1.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.0.1) (0.2.13)\n",
            "Requirement already satisfied: runs in /usr/local/lib/python3.10/dist-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning==2.0.1) (1.2.2)\n",
            "Requirement already satisfied: xmod in /usr/local/lib/python3.10/dist-packages (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning==2.0.1) (1.8.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning==2.0.1) (0.1.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.42 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning==2.0.1) (1.34.43)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning==2.0.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->lightning-cloud>=0.5.31->lightning==2.0.1) (0.10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Data Generator for reading data from list\n",
        "\n",
        "I overwrote data generator for training the model with my custom data which can be simply put into the list\n",
        "\n",
        "1. Make sure you enter your own data in MY_TEXT_DATA list.\n",
        "2. The data in MY_TEXT_DATA will be used for training"
      ],
      "metadata": {
        "id": "N7BkLjMjE0iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd yet-another-retnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4hA_vd0bFfO",
        "outputId": "157c26da-b4f0-40fb-c80c-b576ed681f88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yet-another-retnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Generator, List, Literal, Optional\n",
        "\n",
        "import requests\n",
        "from torch.hub import get_dir\n",
        "from torchdata.datapipes.iter import IterableWrapper, IterDataPipe\n",
        "\n",
        "\n",
        "# Your own text data\n",
        "MY_TEXT_DATA = [\n",
        "    \"AI’s influence on technology is due in part because of how it impacts computing. Through AI, computers have the ability to harness massive amounts of data and use their learned intelligence to make optimal decisions and discoveries in fractions of the time that it would take humans. AI has come a long way since 1951, when the first documented success of an AI computer program was written by Christopher Strachey, whose checkers program completed a whole game on the Ferranti Mark I computer at the University of Manchester. Since then, AI has been used to help sequence RNA for vaccines and model human speech, technologies that rely on model- and algorithm-based machine learning and increasingly focus on perception, reasoning and generalization. With innovations like these, AI has re-taken center stage like never before — and it won’t cede the spotlight anytime soon. \",\n",
        "    \"There’s virtually no major industry that modern AI — more specifically, “narrow AI,” which performs objective functions using data-trained models and often falls into the categories of deep learning or machine learning — hasn’t already affected. That’s especially true in the past few years, as data collection and analysis has ramped up considerably thanks to robust IoT connectivity, the proliferation of connected devices and ever-speedier computer processing.\",\n",
        "    \"With companies spending billions of dollars on AI products and services annually, tech giants like Google, Apple, Microsoft and Amazon spending billions to create those products and services, universities making AI a more prominent part of their curricula and the U.S. Department of Defense upping its AI game, big things are bound to happen. \",\n",
        "]\n",
        "\n",
        "def get_split_indices(\n",
        "    num_samples: int,\n",
        "    split: Literal[\"train\", \"val\", \"test\"],\n",
        "    seed: int = 42,\n",
        "    val_split: float = 0.1,\n",
        "    test_split: float = 0.1,\n",
        ") -> List[int]:\n",
        "    indices = list(range(num_samples))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    num_val = int(num_samples * val_split)\n",
        "    num_test = int(num_samples * test_split)\n",
        "\n",
        "    if split == \"train\":\n",
        "        out = indices[num_val + num_test :]\n",
        "    elif split == \"val\":\n",
        "        out = indices[:num_val]\n",
        "    elif split == \"test\":\n",
        "        out = indices[num_val : num_val + num_test]\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid split: {split}\")\n",
        "\n",
        "    return sorted(out)\n",
        "\n",
        "\n",
        "class TextChunker(IterDataPipe[str]):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dp: IterDataPipe[str],\n",
        "        chunk_size: int = 4096,\n",
        "        step_size: Optional[int] = None,\n",
        "        drop_last: bool = False,\n",
        "    ):\n",
        "        self.dp = dp\n",
        "        self.chunk_size = chunk_size\n",
        "        self.step_size = step_size or chunk_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "    def __iter__(self) -> Generator[str, None, None]:\n",
        "        for text in self.dp:\n",
        "            for i in range(0, len(text), self.step_size):\n",
        "                chunk = text[i : i + self.chunk_size]\n",
        "                if self.drop_last and len(chunk) < self.chunk_size:\n",
        "                    continue\n",
        "\n",
        "                chunk = chunk.split(\" \", maxsplit=1)[-1]  # leading partial words\n",
        "                chunk = chunk.rsplit(\" \", maxsplit=1)[0]  # trailing partial words\n",
        "                chunk = chunk.strip()  # leading/trailing whitespace\n",
        "                yield chunk\n",
        "\n",
        "\n",
        "def my_own_text_datapipe(\n",
        "    split: Literal[\"train\", \"val\", \"test\"],\n",
        "    chunk_size: int = 4096,\n",
        "    step_size: Optional[int] = None,\n",
        "    shuffle: bool = False,\n",
        "    shuffle_buffer_size: int = 8192,\n",
        "    drop_last: bool = True,\n",
        ") -> IterDataPipe[str]:\n",
        "    # Use your own text data instead of URLs\n",
        "    # You can generate your own text or load it from files, databases, etc.\n",
        "    indices = get_split_indices(len(MY_TEXT_DATA), split=split)\n",
        "    if shuffle:\n",
        "        random.shuffle(indices)\n",
        "\n",
        "    # Iterable datapipe of your own text data\n",
        "    pipe: IterDataPipe = IterableWrapper([MY_TEXT_DATA[i] for i in indices])\n",
        "    pipe = TextChunker(\n",
        "        pipe, chunk_size=chunk_size, step_size=step_size, drop_last=drop_last\n",
        "    )\n",
        "    if shuffle:\n",
        "        pipe = pipe.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "    return pipe"
      ],
      "metadata": {
        "id": "QgOeocKeEz-X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "rCHJHLKBDNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd yet-another-retnet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHo65cqfnDdf",
        "outputId": "60fa8c55-a863-4684-8dab-aecfb2769db2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: yet-another-retnet/: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import (\n",
        "    Any,\n",
        "    Callable,\n",
        "    Dict,\n",
        "    Iterator,\n",
        "    List,\n",
        "    Literal,\n",
        "    Optional,\n",
        "    Sequence,\n",
        "    Tuple,\n",
        "    Union,\n",
        ")\n",
        "\n",
        "import tiktoken\n",
        "import torch\n",
        "from lightning import Fabric, seed_everything\n",
        "from lightning.fabric.loggers import TensorBoardLogger\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from yet_another_retnet.retnet import RetNet"
      ],
      "metadata": {
        "id": "SALnsmw_uDuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define tokenizer\n",
        "We have used opensource gpt2, you can also use gpt3 embeddings if you have openai balance"
      ],
      "metadata": {
        "id": "qAGmiSowin84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "TOKENIZER = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "Wzn4MB4muDxN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(\n",
        "    batch: List[str],\n",
        "    max_length: int = 1024,\n",
        "    device: Optional[Union[torch.device, str]] = None,\n",
        ") -> Tuple[Tensor, Tensor]:\n",
        "    x = torch.zeros(len(batch), max_length, device=device, dtype=torch.long)\n",
        "    y = torch.zeros(len(batch), max_length, device=device, dtype=torch.long)\n",
        "\n",
        "    for i, text in enumerate(batch):\n",
        "        encoding = torch.as_tensor(\n",
        "            TOKENIZER.encode(text), device=device, dtype=torch.long\n",
        "        )\n",
        "        seq_length = min(len(encoding) - 1, max_length)\n",
        "        x[i, :seq_length] = encoding[:seq_length]\n",
        "        y[i, :seq_length] = encoding[1 : seq_length + 1]\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "VUOMWyu-uDzV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainingState:\n",
        "    fabric: Fabric\n",
        "    model: RetNet\n",
        "    optimizer: torch.optim.Optimizer\n",
        "    callbacks: Sequence[Callable[[\"TrainingState\", float], None]] = ()\n",
        "\n",
        "    current_step: int = 0\n",
        "    current_epoch: int = 0\n",
        "    accumulate_grad_batches: int = 1\n",
        "    monitor: str = \"val_loss\"\n",
        "    monitor_mode: Literal[\"min\", \"max\"] = \"min\""
      ],
      "metadata": {
        "id": "-eElzh_Zu6ZE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelCheckpoint:\n",
        "    state_dict: Dict[str, Tensor]\n",
        "    optimizer_state: Dict[str, Tensor]\n",
        "    current_step: int\n",
        "    current_epoch: int\n",
        "\n",
        "    @classmethod\n",
        "    def from_training_state(cls, state: TrainingState) -> \"ModelCheckpoint\":\n",
        "        return cls(\n",
        "            state_dict=state.model.state_dict(),\n",
        "            optimizer_state=state.optimizer.state_dict(),\n",
        "            current_step=state.current_step,\n",
        "            current_epoch=state.current_epoch,\n",
        "        )\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"state_dict\": self.state_dict,\n",
        "            \"optimizer_state\": self.optimizer_state,\n",
        "            \"current_step\": self.current_step,\n",
        "            \"current_epoch\": self.current_epoch,\n",
        "        }\n",
        "\n",
        "    def save(self, path: str) -> None:\n",
        "        torch.save(self.to_dict(), path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: str) -> \"ModelCheckpoint\":\n",
        "        checkpoint_dict = torch.load(path)\n",
        "        return cls(**checkpoint_dict)"
      ],
      "metadata": {
        "id": "rJjNdxb0u8yo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckpointCallback:\n",
        "    def __init__(\n",
        "        self, save_dir: str, name: str = \"checkpoint_epoch-{epoch:03d}.pt\"\n",
        "    ) -> None:\n",
        "        self.save_dir = save_dir\n",
        "        self.name = name\n",
        "        self.best_path: Optional[str] = None\n",
        "        self.best_loss: Optional[float] = None\n",
        "\n",
        "    def __call__(self, state: TrainingState, loss: float) -> None:\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        fabric = state.fabric\n",
        "        # 'local_rank == 0' means this only happens for the main process\n",
        "        if fabric.local_rank == 0 and loss <= self.best_loss:\n",
        "            checkpoint = ModelCheckpoint.from_training_state(state)\n",
        "            self.best_loss = loss\n",
        "            if self.best_path is not None:\n",
        "                os.remove(self.best_path)\n",
        "            self.best_path = os.path.join(\n",
        "                self.save_dir, self.name.format(epoch=state.current_epoch)\n",
        "            )\n",
        "            torch.save(checkpoint, self.best_path)\n",
        "\n",
        "        # All processes wait for main to finish saving the checkpoint.\n",
        "        fabric.barrier()"
      ],
      "metadata": {
        "id": "0I5nctWKvB0G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    state: TrainingState,\n",
        "    train_dataloader: DataLoader,\n",
        "    val_dataloader: DataLoader,\n",
        "    log_frequency: int = 25,\n",
        ") -> None:\n",
        "    state.current_epoch += 1\n",
        "    fabric, model, optimizer = state.fabric, state.model, state.optimizer\n",
        "    is_main_process = fabric.local_rank == 0\n",
        "    is_training = model.training\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(\n",
        "        desc=f\"Ep: {state.current_epoch}\", disable=(not is_main_process)\n",
        "    ) as progbar:\n",
        "        train_loss, val_loss = 0.0, 0.0\n",
        "        for x, y in train_dataloader:\n",
        "            state.current_step += 1\n",
        "            accumulating = state.current_step % state.accumulate_grad_batches != 0\n",
        "            with fabric.no_backward_sync(model, enabled=accumulating):  # type: ignore\n",
        "                loss = model.forward(inputs=x, labels=y)\n",
        "                fabric.backward(loss)\n",
        "\n",
        "            if not accumulating:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if state.current_step % log_frequency == 0:\n",
        "                fabric.log(\"loss\", loss, step=state.current_step)\n",
        "                train_loss = loss.item()\n",
        "                progbar.set_postfix_str(f\"loss={train_loss:.4f}\", refresh=False)\n",
        "            progbar.update(1)\n",
        "\n",
        "        model.eval()\n",
        "        val_progbar = tqdm(desc=\"val\", position=1, leave=False)\n",
        "        for i, (x, y) in enumerate(val_dataloader):\n",
        "            with torch.inference_mode():\n",
        "                loss = model.forward(inputs=x, labels=y)\n",
        "            val_loss = (val_loss * i + loss.item()) / (i + 1)\n",
        "\n",
        "            if i % log_frequency == 0:\n",
        "                val_progbar.set_postfix_str(f\"val_loss={val_loss:.4f}\", refresh=False)\n",
        "            val_progbar.update(1)\n",
        "            progbar.update(1)\n",
        "\n",
        "        fabric.log(\"val_loss\", val_loss, step=state.current_step)\n",
        "        val_progbar.close()\n",
        "        progbar.set_postfix_str(\n",
        "            f\"loss={train_loss:.4f}, val_loss={val_loss:.4f}\", refresh=False\n",
        "        )\n",
        "\n",
        "        for callback in state.callbacks:\n",
        "            callback(state, val_loss)\n",
        "\n",
        "        # Return model to its original training state\n",
        "        model.train(mode=is_training)\n",
        "\n"
      ],
      "metadata": {
        "id": "0xuukYUevF-0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    retnet: RetNet,\n",
        "    train_dataloader: DataLoader,\n",
        "    val_dataloader: DataLoader,\n",
        "    accelerator: str = \"auto\",\n",
        "    strategy: str = \"auto\",\n",
        "    precision: Optional[str] = None,\n",
        "    epochs: int = 1,\n",
        "    lr: float = 3e-2,\n",
        "    log_frequency: int = 25,\n",
        "):\n",
        "    if precision is None:\n",
        "        if torch.cuda.is_available():\n",
        "            # use bfloat16 if supported\n",
        "            version, _ = torch.cuda.get_device_capability()\n",
        "            precision = \"bf16-mixed\" if version >= 8 else \"16-mixed\"\n",
        "        else:\n",
        "            precision = \"32-true\"\n",
        "\n",
        "    logger = TensorBoardLogger(root_dir=\"./\")\n",
        "    fabric = Fabric(\n",
        "        accelerator=accelerator,\n",
        "        strategy=strategy,\n",
        "        precision=precision,  # type: ignore\n",
        "        loggers=[logger],\n",
        "    )\n",
        "    fabric.launch()\n",
        "    print(f\"Experiment version: {logger.version}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Setup with fabric.\n",
        "    optimizer = torch.optim.AdamW(retnet.parameters(), lr=lr)\n",
        "    retnet, optimizer = fabric.setup(retnet, optimizer)\n",
        "    train_dataloader, val_dataloader = fabric.setup_dataloaders(\n",
        "        train_dataloader, val_dataloader\n",
        "    )\n",
        "    # Construct a training state and run the training loop.\n",
        "    state = TrainingState(\n",
        "        fabric=fabric,\n",
        "        model=retnet,\n",
        "        optimizer=optimizer,\n",
        "        callbacks=[CheckpointCallback(save_dir=logger.log_dir)],\n",
        "    )\n",
        "    for _ in range(epochs):\n",
        "        train_one_epoch(\n",
        "            state=state,\n",
        "            train_dataloader=train_dataloader,\n",
        "            val_dataloader=val_dataloader,\n",
        "            log_frequency=log_frequency,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "QbME1o4kvKBW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    retnet: RetNet,\n",
        "    prompt: str,\n",
        "    prompt_chunk_size: Optional[int] = None,\n",
        "    max_new_tokens: int = 1024,\n",
        "    stop_tokens: Sequence[str] = (),\n",
        "    top_k: int = 5,\n",
        "    temperature: float = 1.0,\n",
        "    seed: int = 42,\n",
        ") -> Iterator[str]:\n",
        "    seed_everything(seed)\n",
        "    device = next(iter(retnet.parameters())).device\n",
        "    is_training = retnet.training\n",
        "    retnet.eval()\n",
        "\n",
        "    # Tokenize the prompt and convert to a tensor.\n",
        "    tokenized = TOKENIZER.encode(prompt)\n",
        "    x = torch.as_tensor(tokenized, dtype=torch.long, device=device).unsqueeze_(0)\n",
        "\n",
        "    if not prompt_chunk_size:\n",
        "        prompt_chunk_size = x.size(1)\n",
        "\n",
        "    prev_states: List[Optional[Tensor]] = [None] * retnet.num_layers\n",
        "    start_idx: int = 0\n",
        "    for start_idx in range(0, x.size(1), prompt_chunk_size):\n",
        "        y, prev_states = retnet.forward_chunkwise(  # type: ignore\n",
        "            x, start_idx=start_idx, prev_states=prev_states\n",
        "        )\n",
        "        y = y[:, -1]\n",
        "\n",
        "    # Generate tokens until we reach the maximum number of tokens or a stop token.\n",
        "    for i in range(max_new_tokens):\n",
        "        probs: Tensor = torch.softmax(y.squeeze() / max(temperature, 1e-8), dim=-1)\n",
        "        # Get top-k tokens, renormalize their probabilities, and weighted sample.\n",
        "        tokens: Tensor  # for mypy\n",
        "        probs, tokens = probs.topk(k=top_k, dim=-1)\n",
        "        probs /= probs.sum()\n",
        "\n",
        "        # Take weighted random sample from the top-k tokens.\n",
        "        sampled_idx: int = torch.multinomial(probs, num_samples=1).item()  # type: ignore\n",
        "        token: int = tokens[sampled_idx].item()  # type: ignore\n",
        "        tokenized.append(token)\n",
        "        yield TOKENIZER.decode(tokenized)\n",
        "\n",
        "        token_str: str = TOKENIZER.decode([token])\n",
        "        if token_str in stop_tokens:\n",
        "            break\n",
        "        elif i < (max_new_tokens - 1):\n",
        "            start_idx += 1\n",
        "            x = torch.as_tensor([token], dtype=torch.long, device=device)\n",
        "            y, prev_states = retnet.forward_recurrent(  # type: ignore\n",
        "                x, start_idx, prev_states=prev_states\n",
        "            )\n",
        "\n",
        "    # Restore the model's original training state.\n",
        "    retnet.train(mode=is_training)\n"
      ],
      "metadata": {
        "id": "UlYRQiS9vPdR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse custom data using data loader\n",
        "\n",
        "1. We will use our custom data pipeline and print one chunk of it to see how the data is being ingested to our model.\n",
        "\n",
        "You can uncomment collate fn if you want to see tokens instead of words."
      ],
      "metadata": {
        "id": "7qfhyOixi2zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "            my_own_text_datapipe(\n",
        "                split=\"train\",\n",
        "                chunk_size=64,\n",
        "                step_size=2,\n",
        "                shuffle=True,\n",
        "                drop_last=True,\n",
        "            ),\n",
        "            #collate_fn=collate_fn,\n",
        "            batch_size=1,\n",
        "            drop_last=True,\n",
        "        )"
      ],
      "metadata": {
        "id": "uACn28pxM1sY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, text_chunk in enumerate(train_dataloader):\n",
        "    print(f\"Chunk {i + 1}: {text_chunk}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qtOVW-GP7Lx",
        "outputId": "66cb1ad8-fa66-44f3-ab93-406acb566d38"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: ['machine learning and increasingly focus on perception,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Function to train our model"
      ],
      "metadata": {
        "id": "NhC71_61jXBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    model_checkpoint: Optional[str] = None,\n",
        "    accelerator: str = \"auto\",\n",
        "    strategy: str = \"auto\",\n",
        "    precision: Optional[str] = None,\n",
        "    epochs: int = 1,\n",
        "    batch_size: int = 4,\n",
        "    lr: float = 3e-4,\n",
        "    log_frequency: int = 25,\n",
        "    seed: int = 42,\n",
        "    eval_only: bool = False,\n",
        "    eval_prompt: str = 'AI is a branch of computer science ',\n",
        "    eval_max_tokens: int = 128,\n",
        "):\n",
        "    seed_everything(seed)\n",
        "    # Create a (relatively small) model and dataloaders\n",
        "    retnet = RetNet(\n",
        "        num_tokens=TOKENIZER.n_vocab,\n",
        "        d_model=768,\n",
        "        nhead=8,\n",
        "        num_layers=12,\n",
        "    )\n",
        "    if model_checkpoint is not None:\n",
        "        retnet.load_state_dict(ModelCheckpoint.load(model_checkpoint).state_dict)\n",
        "\n",
        "    if not eval_only:\n",
        "        num_devices = torch.cuda.device_count()\n",
        "        if num_devices > 0:\n",
        "            # Lightning Fabric does not scale the batch size for distributed training.\n",
        "            # In order to keep batch size the same, divide by the number of devices.\n",
        "            if batch_size % num_devices != 0:\n",
        "                raise ValueError(f\"{batch_size=} must be divisible by {num_devices=}.\")\n",
        "            batch_size = batch_size // num_devices\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            my_own_text_datapipe(\n",
        "                split=\"train\",\n",
        "                chunk_size=28,\n",
        "                step_size=32,\n",
        "                shuffle=True,\n",
        "                drop_last=True,\n",
        "            ),\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=collate_fn,\n",
        "            drop_last=True,\n",
        "        )\n",
        "        val_dataloader = DataLoader(\n",
        "            my_own_text_datapipe(\n",
        "                split=\"val\", chunk_size=28, step_size=32\n",
        "            ),\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=collate_fn,\n",
        "        )\n",
        "\n",
        "        train(\n",
        "            retnet=retnet,\n",
        "            train_dataloader=train_dataloader,\n",
        "            val_dataloader=val_dataloader,\n",
        "            accelerator=accelerator,\n",
        "            strategy=strategy,\n",
        "            precision=precision,\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            log_frequency=log_frequency,\n",
        "        )\n",
        "\n",
        "    # Generate some text\n",
        "    prev_output: str = \"\"\n",
        "    for output in generate(retnet, eval_prompt, max_new_tokens=eval_max_tokens):\n",
        "        # Return to the start of the line and print the output (no newline)\n",
        "        print(output[len(prev_output) :], end=\"\", flush=True)\n",
        "        prev_output = output\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "midX8YnivS9u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Training / Inference\n",
        "If you just want to evaluate model without training use main(eval_only = True)"
      ],
      "metadata": {
        "id": "gNhI17-HjbjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model will continue writing on the below prompt\n",
        "EVAL_PROMPT = \"Artificiall intelligence is \""
      ],
      "metadata": {
        "id": "jlx741Gij1s6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure to adjust args as per your requirements\n",
        "\n",
        "main(eval_prompt=EVAL_PROMPT)\n",
        "#main(eval_prompt=EVAL_PROMPT, eval_only=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TLb6nrTvW8Y",
        "outputId": "ba4e35cd-7930-439c-82a5-7cd504b8189d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 42\n",
            "WARNING: Missing logger folder: ./lightning_logs\n",
            "WARNING:lightning.fabric.loggers.tensorboard:Missing logger folder: ./lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment version: 0\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep: 1: 1it [01:18, 78.22s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLbrT1OGvfdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}